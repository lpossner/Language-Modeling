{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:56:49.793695Z",
     "iopub.status.busy": "2024-09-25T08:56:49.793326Z",
     "iopub.status.idle": "2024-09-25T08:56:49.800450Z",
     "shell.execute_reply": "2024-09-25T08:56:49.798913Z",
     "shell.execute_reply.started": "2024-09-25T08:56:49.793657Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import kagglehub\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "import evaluate\n",
    "\n",
    "from peft import LoraConfig, TaskType, get_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:56:49.802246Z",
     "iopub.status.busy": "2024-09-25T08:56:49.801948Z",
     "iopub.status.idle": "2024-09-25T08:56:49.812536Z",
     "shell.execute_reply": "2024-09-25T08:56:49.811701Z",
     "shell.execute_reply.started": "2024-09-25T08:56:49.802214Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_ckpt = \"microsoft/deberta-v3-base\"\n",
    "# model_ckpt = \"distilbert-base-uncased\"\n",
    "# model_ckpt = \"microsoft/deberta-v3-large\"\n",
    "# model_ckpt = \"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
    "# model_ckpt = \"vinai/bertweet-base\"\n",
    "\n",
    "results_path = os.path.join(\"results\" \"disaster-tweets\")\n",
    "\n",
    "# Training parameters\n",
    "epochs = 20\n",
    "batch_size = 128\n",
    "learning_rate = 5e-5\n",
    "weight_decay = 1e-4\n",
    "warmup_ratio = 0.0\n",
    "max_length = 64\n",
    "\n",
    "# LORA parameters\n",
    "r = 8\n",
    "lora_alpha = 32\n",
    "target_modules = [\"query_proj\", \"key_proj\", \"value_proj\"]\n",
    "lora_dropout = 0.3\n",
    "bias = \"none\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:56:49.814352Z",
     "iopub.status.busy": "2024-09-25T08:56:49.813922Z",
     "iopub.status.idle": "2024-09-25T08:57:00.480318Z",
     "shell.execute_reply": "2024-09-25T08:57:00.479360Z",
     "shell.execute_reply.started": "2024-09-25T08:56:49.814293Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_path = kagglehub.competition_download(\"nlp-getting-started\")\n",
    "\n",
    "train_df = pd.read_csv(os.path.join(data_path, \"train.csv\"))\n",
    "train_df = train_df.drop(columns=[\"id\", \"keyword\", \"location\"])\n",
    "train_df = train_df.rename(columns={\"target\": \"labels\"})\n",
    "train_dataset_train_eval = Dataset.from_pandas(train_df).train_test_split(\n",
    "    train_size=0.9\n",
    ")\n",
    "train_dataset = train_dataset_train_eval[\"train\"]\n",
    "eval_dataset = train_dataset_train_eval[\"test\"]\n",
    "\n",
    "test_df = pd.read_csv(os.path.join(data_path, \"test.csv\"))\n",
    "submission_df = test_df[[\"id\"]]\n",
    "test_df = test_df.drop(columns=[\"id\", \"keyword\", \"location\"])\n",
    "test_df = test_df.rename(columns={\"target\": \"labels\"})\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "print(\"Train dataset shape:\", train_dataset.shape)\n",
    "print(\"Eval dataset shape:\", eval_dataset.shape)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_ckpt, use_fast=False, clean_up_tokenization_spaces=True\n",
    ")\n",
    "\n",
    "tokenize = lambda batch: tokenizer(\n",
    "    batch[\"text\"],\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=max_length,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "\n",
    "tokenized_train_dataset = train_dataset.map(\n",
    "    tokenize, batched=True, batch_size=batch_size\n",
    ")\n",
    "tokenized_eval_dataset = eval_dataset.map(tokenize, batched=True, batch_size=batch_size)\n",
    "\n",
    "tokenized_test_dataset = test_dataset.map(tokenize, batched=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:57:00.482852Z",
     "iopub.status.busy": "2024-09-25T08:57:00.482492Z",
     "iopub.status.idle": "2024-09-25T08:57:02.279132Z",
     "shell.execute_reply": "2024-09-25T08:57:02.278151Z",
     "shell.execute_reply.started": "2024-09-25T08:57:00.482813Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_name = model_ckpt.split(\"/\")[-1] + \"_disaster_tweets\"\n",
    "\n",
    "device = torch.device(\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")\n",
    "\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "precision_metric = evaluate.load(\"precision\")\n",
    "recall_metric = evaluate.load(\"recall\")\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)[\n",
    "        \"accuracy\"\n",
    "    ]\n",
    "    precision = precision_metric.compute(\n",
    "        predictions=predictions, references=labels, average=\"binary\"\n",
    "    )[\"precision\"]\n",
    "    recall = recall_metric.compute(\n",
    "        predictions=predictions, references=labels, average=\"binary\"\n",
    "    )[\"recall\"]\n",
    "    f1 = f1_metric.compute(\n",
    "        predictions=predictions, references=labels, average=\"binary\"\n",
    "    )[\"f1\"]\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:57:02.280931Z",
     "iopub.status.busy": "2024-09-25T08:57:02.280491Z",
     "iopub.status.idle": "2024-09-25T08:57:03.020727Z",
     "shell.execute_reply": "2024-09-25T08:57:03.019827Z",
     "shell.execute_reply.started": "2024-09-25T08:57:02.280880Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_ckpt, num_labels=len(set(train_dataset[\"labels\"]))\n",
    ")\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    r=r,\n",
    "    lora_alpha=lora_alpha,\n",
    "    target_modules=target_modules,\n",
    "    lora_dropout=lora_dropout,\n",
    "    bias=bias,\n",
    ")\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# for param in model.base_model.parameters():\n",
    "# param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:57:03.022556Z",
     "iopub.status.busy": "2024-09-25T08:57:03.022146Z",
     "iopub.status.idle": "2024-09-25T09:11:47.255938Z",
     "shell.execute_reply": "2024-09-25T09:11:47.254941Z",
     "shell.execute_reply.started": "2024-09-25T08:57:03.022507Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=results_path,\n",
    "    logging_dir=os.path.join(results_path, \"logs\"),\n",
    "    logging_strategy=\"epoch\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    metric_for_best_model=\"f1\",\n",
    "    learning_rate=learning_rate,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    num_train_epochs=epochs,\n",
    "    weight_decay=weight_decay,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    load_best_model_at_end=True,\n",
    "    disable_tqdm=False,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "trainer.evaluate()\n",
    "\n",
    "trainer.model.save_pretrained(os.path.join(results_path, model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T09:11:47.257483Z",
     "iopub.status.busy": "2024-09-25T09:11:47.257184Z",
     "iopub.status.idle": "2024-09-25T09:11:55.548725Z",
     "shell.execute_reply": "2024-09-25T09:11:55.547816Z",
     "shell.execute_reply.started": "2024-09-25T09:11:47.257450Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_prediction = trainer.predict(tokenized_test_dataset)\n",
    "predictions = np.argmax(model_prediction.predictions, axis=-1)\n",
    "\n",
    "submission_df[\"target\"] = predictions\n",
    "submission_df.to_csv(os.path.join(results_path, \"submission.csv\"), index=False)\n",
    "\n",
    "submission_df"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 869809,
     "sourceId": 17777,
     "sourceType": "competition"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "language-modelling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
